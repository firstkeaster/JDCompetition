{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangruofan/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkthisvb(vb):\n",
    "    spm = pd.DataFrame(origdata.groupby(vb)['is_risk'].mean())\n",
    "    cnt = pd.DataFrame(origdata.groupby(vb)['is_risk'].count())\n",
    "    # cityspm.reset_index(inplace = True)\n",
    "    spm = pd.merge(spm, cnt, left_index=True, right_index=True)\n",
    "    spm = spm.rename(columns = {\"is_risk_x\": \"riskprob\", \"is_risk_y\":\"count\"})\n",
    "    spm = spm.sort_values(by = \"is_risk\", ascending=False)\n",
    "    return spm\n",
    "def changehour(x):\n",
    "    if x['hour'] >= 3 and x['hour'] <= 5:\n",
    "        return 3\n",
    "    elif x['hour'] == 2 or x['hour'] == 6:\n",
    "        return 2\n",
    "    else: \n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainprocess(data):\n",
    "    data['hour'] = data.apply(changehour, axis = 1)\n",
    "    dv = pd.DataFrame({\"dev\":data.groupby(\"device\")['is_risk'].mean()})\n",
    "    data = data.merge(dv, left_on=\"device\", right_index=True, how = \"left\")\n",
    "    data.drop(\"device\", 1, inplace=True)\n",
    "    # data['dev'] = data.apply(lambda x : 1 if x[\"dev\"] > 0.7 else 0, axis = 1)\n",
    "\n",
    "    iddt = pd.DataFrame({\"idp\":data.groupby(\"id\")['is_risk'].mean()})\n",
    "    data = data.merge(iddt, left_on=\"id\", right_index=True, how = \"left\")\n",
    "    data.drop(\"id\", 1, inplace=True)\n",
    "\n",
    "    city = pd.DataFrame({\"ct\":data.groupby(\"city\")['is_risk'].mean()})\n",
    "    data = data.merge(city, left_on=\"city\", right_index=True, how = \"left\")\n",
    "    data.drop(\"city\", 1, inplace=True)\n",
    "    data['ct'] = data.apply(lambda x : 1 if x[\"ct\"] > 0.07 else 0, axis = 1)\n",
    "\n",
    "    ip = pd.DataFrame({\"ipa\":data.groupby(\"ip\")['is_risk'].mean()})\n",
    "    data = data.merge(ip, left_on=\"ip\", right_index=True, how = \"left\")\n",
    "    # data.drop(\"ip\", 1, inplace=True)\n",
    "    data['ipa'] = data.apply(lambda x : 1 if x[\"ipa\"] > 0 else 0, axis = 1)\n",
    "\n",
    "    log = pd.DataFrame({\"log\":data.groupby(\"log_from\")['is_risk'].mean()})\n",
    "    data = data.merge(log, left_on=\"log_from\", right_index=True, how = \"left\")\n",
    "    # data.drop(\"log_from\", 1, inplace=True)\n",
    "    data['log'] = data.apply(lambda x : 1 if x[\"log\"] > 0 else 0, axis = 1)\n",
    "    res = pd.DataFrame({\"res\":data.groupby(\"result\")['is_risk'].mean()})\n",
    "    data = data.merge(res, left_on=\"result\", right_index=True, how = \"left\")\n",
    "    columns_one_hot = ['type', 'result','weekdays',\"log_from\"]\n",
    "    for col in columns_one_hot:      \n",
    "        data = data.join(pd.get_dummies(data[col], prefix=col))\n",
    "    data.drop(columns_one_hot, axis=1, inplace=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.read_csv(\"Dec10/train11.csv\", index_col=0)\n",
    "traindata = trainprocess(traindata)\n",
    "traindata.to_csv('train_aft.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testprocess(data, origdata):\n",
    "    data['hour'] = data.apply(changehour, axis = 1)\n",
    "\n",
    "    dv = pd.DataFrame({\"dev\":origdata.groupby(\"device\")['is_risk'].mean()})\n",
    "    data = data.merge(dv, left_on=\"device\", right_index=True, how = \"left\")\n",
    "    data.drop(\"device\", 1, inplace=True)\n",
    "    # data['dev'] = data.apply(lambda x : 1 if x[\"dev\"] > 0.7 else 0, axis = 1)\n",
    "\n",
    "    iddt = pd.DataFrame({\"idp\":origdata.groupby(\"id\")['is_risk'].mean()})\n",
    "    data = data.merge(iddt, left_on=\"id\", right_index=True, how = \"left\")\n",
    "    data.drop(\"id\", 1, inplace=True)\n",
    "\n",
    "    city = pd.DataFrame({\"ct\":origdata.groupby(\"city\")['is_risk'].mean()})\n",
    "    data = data.merge(city, left_on=\"city\", right_index=True, how = \"left\")\n",
    "    data.drop(\"city\", 1, inplace=True)\n",
    "    data['ct'] = data.apply(lambda x : 1 if x[\"ct\"] > 0.07 else 0, axis = 1)\n",
    "\n",
    "    ip = pd.DataFrame({\"ipa\":origdata.groupby(\"ip\")['is_risk'].mean()})\n",
    "    data = data.merge(ip, left_on=\"ip\", right_index=True, how = \"left\")\n",
    "    # data.drop(\"ip\", 1, inplace=True)\n",
    "    data['ipa'] = data.apply(lambda x : 1 if x[\"ipa\"] > 0 else 0, axis = 1)\n",
    "\n",
    "    log = pd.DataFrame({\"log\":origdata.groupby(\"log_from\")['is_risk'].mean()})\n",
    "    data = data.merge(log, left_on=\"log_from\", right_index=True, how = \"left\")\n",
    "    # data.drop(\"log_from\", 1, inplace=True)\n",
    "    data['log'] = data.apply(lambda x : 1 if x[\"log\"] > 0 else 0, axis = 1)\n",
    "\n",
    "    # data.weekdays = data.weekdays.replace([1,0,2,4,5,6,3], [0,0,0,1,0,0,0])\n",
    "    res = pd.DataFrame({\"res\":origdata.groupby(\"result\")['is_risk'].mean()})\n",
    "    data = data.merge(res, left_on=\"result\", right_index=True, how = \"left\")\n",
    "    columns_one_hot = ['type', 'result','weekdays', \"log_from\"]\n",
    "    for col in columns_one_hot:      \n",
    "        data = data.join(pd.get_dummies(data[col], prefix=col))\n",
    "    data.drop(columns_one_hot, axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = pd.read_csv(\"Dec10/test11.csv\", index_col=0)\n",
    "origdata = pd.read_csv(\"Dec10/train11.csv\", index_col=0)\n",
    "testdata = testprocess(testdata, origdata)\n",
    "testdata.to_csv('test_aft.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(train, test):\n",
    "    X_train = train.drop([\"is_risk\"], 1)\n",
    "    Y_train = train.is_risk\n",
    "    filt1 = train.dev > 0\n",
    "    filt2 = train.idp > 0\n",
    "    filt3 = train.ct > 0\n",
    "    filt4 = train.ipa > 0\n",
    "    test = test.fillna({\"dev\":np.mean(train[filt1].dev),\"idp\":np.mean(train[filt2].idp),\"ct\":np.mean(train[filt3].ct)})\n",
    "    X_test = test\n",
    "#         Y_test = test.is_risk\n",
    "    cols = X_train.columns.tolist()\n",
    "    cols2 = X_test.columns.tolist()\n",
    "    X_train = X_train[cols2]\n",
    "    X_train['time_pd_x']=[pd.Timestamp(X_train.loc[t,'time_pd_x']) for t in X_train.index]\n",
    "    X_train['time_pd_y']=[pd.Timestamp(X_train.loc[t,'time_pd_y']) for t in X_train.index]\n",
    "    X_test['time_pd_x']=[pd.Timestamp(X_test.loc[t,'time_pd_x']) for t in X_test.index]\n",
    "    X_test['time_pd_y']=[pd.Timestamp(X_test.loc[t,'time_pd_y']) for t in X_test.index]\n",
    "    def caltimedif(data):\n",
    "        return (data['time_pd_x'] - data['time_pd_y']).days \n",
    "    X_train['dif'] = X_train.apply(caltimedif, axis = 1)\n",
    "    X_test['dif'] = X_test.apply(caltimedif, axis = 1)\n",
    "    X_train = X_train.drop([\"time_dif\",\"time_pd_x\",\"time_pd_y\"], 1)\n",
    "    X_test = X_test.drop([\"time_dif\",\"time_pd_x\",\"time_pd_y\"], 1)\n",
    "    xg = XGBClassifier(learning_rate =0.11,\n",
    "     n_estimators=150,\n",
    "     max_depth=10,\n",
    "     min_child_weight=1,\n",
    "     gamma=0,\n",
    "     subsample=0.8,\n",
    "     colsample_bytree=0.8,\n",
    "     objective= 'binary:logistic',\n",
    "     nthread=4,\n",
    "     scale_pos_weight=1,\n",
    "     seed=27)\n",
    "    xg.fit(X_train, Y_train)\n",
    "    y_test_hat_xg = xg.predict_proba(X_test)[:,1]\n",
    "    y_test_hat_xg_cl = xg.predict(X_test)\n",
    "    y_train_hat_xg = xg.predict_proba(X_train)[:,1]\n",
    "    # print(fbeta_score(Y_train, y_train_hat_xg, beta=0.1))\n",
    "    # print(fbeta_score(Y_test, y_test_hat_xg_cl, beta=0.1))\n",
    "    Y_test_hat_xg_pr = xg.predict_proba(X_test)\n",
    "    test['prxg'] = Y_test_hat_xg_pr[:,1]\n",
    "    test.to_csv(\"Dec10/test1xg.csv\")\n",
    "    return test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_aft.csv\",index_col=0)\n",
    "test = pd.read_csv(\"test_aft.csv\",index_col=0)\n",
    "result = model(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rowkey\n",
       "24622     0.000031\n",
       "39036     0.000042\n",
       "62674     0.000041\n",
       "163053    0.000054\n",
       "50616     0.000045\n",
       "68355     0.000244\n",
       "23239     0.000004\n",
       "94869     0.000003\n",
       "79351     0.007103\n",
       "81268     0.139674\n",
       "172474    0.000029\n",
       "55344     0.000463\n",
       "111852    0.000429\n",
       "111911    0.000429\n",
       "1124      0.000011\n",
       "61060     0.000011\n",
       "83879     0.000044\n",
       "109683    0.000004\n",
       "38326     0.000059\n",
       "43939     0.000029\n",
       "69235     0.000029\n",
       "125353    0.000030\n",
       "54412     0.000333\n",
       "154863    0.000004\n",
       "101241    0.000635\n",
       "66271     0.000051\n",
       "166319    0.000043\n",
       "118449    0.000404\n",
       "119214    0.000404\n",
       "136995    0.000176\n",
       "            ...   \n",
       "78404     0.000008\n",
       "164721    0.000004\n",
       "82822     0.000069\n",
       "82864     0.000069\n",
       "108438    0.000219\n",
       "148460    0.000422\n",
       "155564    0.000542\n",
       "4236      0.000006\n",
       "58202     0.000007\n",
       "9028      0.000337\n",
       "62456     0.000126\n",
       "42239     0.000020\n",
       "85560     0.000004\n",
       "91511     0.000005\n",
       "145621    0.000005\n",
       "46113     0.000006\n",
       "60326     0.000005\n",
       "128092    0.000029\n",
       "128215    0.000029\n",
       "153848    0.000028\n",
       "22946     0.000007\n",
       "138352    0.000006\n",
       "34651     0.000106\n",
       "34724     0.000106\n",
       "34832     0.000095\n",
       "51818     0.000069\n",
       "56833     0.000066\n",
       "125947    0.000027\n",
       "115032    0.000016\n",
       "17344     0.000004\n",
       "Name: prxg, Length: 17875, dtype: float32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.prxg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
